{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticAnalysisBlackcoffer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8TRJ1n6wPog"
      },
      "source": [
        "# Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_sWfMFDwTf0"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import string\n",
        "import time\n",
        "from nltk.tokenize import sent_tokenize, RegexpTokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcCZF-iHApB4",
        "outputId": "cd6756fa-b392-42b8-8f72-938108dcd440"
      },
      "source": [
        "!pip3 install requests"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyFgrd8nwjgI"
      },
      "source": [
        "# Importing cik List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYfyRiSCwjG0"
      },
      "source": [
        "cik_list = pd.read_csv('cik_list.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aez0FGoAw3nK"
      },
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm2jSK2XwiAw"
      },
      "source": [
        "def extract_data(link):\n",
        "    link = 'https://www.sec.gov/Archives/' + link.strip()\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"}\n",
        "    f = requests.get('https://www.sec.gov/Archives/' ,headers=headers)\n",
        "    text = f.text\n",
        "    return text\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "zZfOSX9FFcFA",
        "outputId": "aa9cd5ed-925f-4651-fa1d-23363e37ddff"
      },
      "source": [
        "report=cik_list['SECFNAME'].apply(extract_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a48c233ac0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcik_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SECFNAME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-ba14dbb3c126>\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(link)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.sec.gov/Archives/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.sec.gov/Archives/'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xec3hfWxLVk"
      },
      "source": [
        "def clean_data(text):\n",
        "    #Remove HTML Tags\n",
        "    text = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});','', text)\n",
        "    \n",
        "    #remove extra line and tabs\n",
        "    text = text.replace('\\n',' ')\n",
        "    text = text.replace('\\t',' ')\n",
        "\n",
        "    #remove punctuation \n",
        "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # remove numbers and special characters\n",
        "    text = re.sub(r'[^a-zA-z.,!?/:;\\\"\\'\\s]',' ',text)\n",
        "    \n",
        "    #remove multiple spaces\n",
        "    text = re.sub('(?s) +',' ',text)\n",
        "   \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKGL9sYDxd9p"
      },
      "source": [
        "report_data = {'raw_text': report}\n",
        "report_df = pd.DataFrame(report_data)\n",
        "report_df['clean_data'] = report_df['raw_text'].apply(clean_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_l1rRzkxJ29"
      },
      "source": [
        "Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG6FrrcFxrXU"
      },
      "source": [
        "f = open(\"StopWords_Generic.txt\", \"r\")\n",
        "stop_words = f.read().lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYDryESFyVXM"
      },
      "source": [
        "stopWordList = stop_words.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWy46622yZcU"
      },
      "source": [
        "def tokenize_text(text):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+') #removing punctuation\n",
        "    tokens = tokenizer.tokenize(text.lower())\n",
        "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens)) # filtering stopwords\n",
        "    return filtered_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLdpxSKhycLQ"
      },
      "source": [
        "report_df['filtered'] = report_df['clean_data'].apply(tokenize_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFRefukuyfxE"
      },
      "source": [
        "positive_df = pd.read_csv('Positive-Table.csv')\n",
        "negative_df = pd.read_csv('Negative-Table.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYlBBf_oyie_"
      },
      "source": [
        "positiveWords = positive_df['Unnamed: 0'].apply(lambda x:x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvgUH9ivynIH"
      },
      "source": [
        "positiveWordsList = positiveWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOC7kmkHysGK"
      },
      "source": [
        "negativeWords = negative_df['Unnamed: 0'].apply(lambda x:x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Pa_cFryvLr"
      },
      "source": [
        "negativeWordsList = negativeWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWNzAyGayyCg"
      },
      "source": [
        "positiveWordsList = list(filter(lambda word: word not in stopWordList, positiveWordsList))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGJpa1ly1eN"
      },
      "source": [
        "negativeWordsList = list(filter(lambda word: word not in stopWordList, negativeWordsList))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDeI2b7jy78p"
      },
      "source": [
        "Positive and Negative Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKr82as5zAVB"
      },
      "source": [
        "def positive_score(token):\n",
        "    posWords = 0\n",
        "    for word in token:\n",
        "        if word in positiveWordsList:\n",
        "            posWords  += 1\n",
        "    return posWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrlbiB_fzEoq"
      },
      "source": [
        "def negative_score(token):\n",
        "    negWords=0\n",
        "    for word in token:\n",
        "        if word in negativeWordsList:\n",
        "            negWords -=1\n",
        "    return negWords*-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhhZ5t7BzIhL"
      },
      "source": [
        "def polarity_score(positiveScore, negativeScore):\n",
        "    pol_score = (positiveScore - negativeScore) / ((positiveScore + negativeScore) + 0.000001)\n",
        "    return pol_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg0lY7_VzLbu"
      },
      "source": [
        "report_df['positive_score'] = report_df['filtered'].apply(positive_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF4aY0vmzTUH"
      },
      "source": [
        "report_df['negative_score'] = report_df['filtered'].apply(negative_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0Gw7BYzXBf"
      },
      "source": [
        "report_df['polarity_score'] = report_df.apply(lambda x: polarity_score(x.positive_score,x.negative_score),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Xazbwmzaj3"
      },
      "source": [
        "def average_sentence_length(text,word_token):\n",
        "    sentence_token = sent_tokenize(text)\n",
        "    totalWordCount = len(word_token)\n",
        "    totalSentences = len(sentence_token)\n",
        "    average_sent_length = 0\n",
        "    if totalSentences != 0:\n",
        "        average_sent_length = totalWordCount / totalSentences    \n",
        "    return round(average_sent_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUbJm0DczeGv"
      },
      "source": [
        "report_df['average_sentence_length'] = report_df.apply(lambda x: average_sentence_length(x.clean_data,x.filtered),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3LmapTCzhfs"
      },
      "source": [
        "def syllable_count(word):\n",
        "    vowels = 0\n",
        "    word = word.lower()\n",
        "    if word.endswith(('es','ed')):\n",
        "            pass\n",
        "    else:\n",
        "        for w in word:\n",
        "            if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
        "                vowels += 1\n",
        "    return vowels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbyVod3FzljD"
      },
      "source": [
        "def complex_word_count(token):\n",
        "    complexWords = 0\n",
        "    for word in token:\n",
        "        if syllable_count(word) > 2:\n",
        "            complexWords+=1\n",
        "    return complexWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8IyAR5dzrPz"
      },
      "source": [
        "def complex_word_percentage(token):\n",
        "    totalWords = len(token)\n",
        "    complexWords = complex_word_count(token)\n",
        "    return complexWords/totalWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VOwitJKzu1H"
      },
      "source": [
        "report_df['percentage_of_complex_words'] = report_df['filtered'].apply(complex_word_percentage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB_SUyqfzy0N"
      },
      "source": [
        "def fog_index(avg_sentence_length,percentage_complex):\n",
        "    return 0.4*(avg_sentence_length+percentage_complex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TplRG1qfz2Bc"
      },
      "source": [
        "report_df['fog_index'] = report_df.apply(lambda x:fog_index(x.average_sentence_length,x.percentage_of_complex_words),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2j8C8oZz5ef"
      },
      "source": [
        "report_df['word_count'] = report_df['filtered'].apply(lambda x:len(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOXY5jnSz_xu"
      },
      "source": [
        "report_df['complex_word_count'] = report_df['filtered'].apply(complex_word_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6OKgMGo0DFH"
      },
      "source": [
        "\n",
        "uncertainty_df = pd.read_csv('uncertainty_dictionary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpu_Dfl_0Gpv"
      },
      "source": [
        "uncertainWords = uncertainty_df['Word'].apply(lambda x:x.lower())\n",
        "uncertainWordsList = uncertainWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdtOD4pn0Kbm"
      },
      "source": [
        "def uncertainty_score(token):\n",
        "    uncWords = 0\n",
        "    for word in token:\n",
        "        if word in uncertainWordsList:\n",
        "            uncWords  += 1\n",
        "    return uncWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs64-E1q0NKT"
      },
      "source": [
        "constraining_df = pd.read_csv('constraining_dictionary.csv')\n",
        "constrainWords = constraining_df['Word'].apply(lambda x:x.lower())\n",
        "constrainWordsList = constrainWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTqigUtd0P3z"
      },
      "source": [
        "def constraining_score(token):\n",
        "    constrainWords = 0\n",
        "    for word in token:\n",
        "        if word in constrainWordsList:\n",
        "            constrainWords  += 1\n",
        "    return constrainWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JTxC2DW0SoO"
      },
      "source": [
        "report_df['uncertainty_score'] = report_df['filtered'].apply(uncertainty_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC7eCP_i0VxD"
      },
      "source": [
        "report_df['constraining_score'] = report_df['filtered'].apply(constraining_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2m4QMDz0YxD"
      },
      "source": [
        "def positive_word_proportion(positiveScore,wordcount):\n",
        "    pwp = 0\n",
        "    if wordcount !=0:\n",
        "        pwp = positiveScore / wordcount\n",
        "    return pwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7bqsKcm0bWL"
      },
      "source": [
        "def negative_word_proportion(negativeScore,wordcount):\n",
        "    nwp = 0\n",
        "    if wordcount !=0:\n",
        "        nwp = negativeScore / wordcount\n",
        "    return nwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJNvHtKf0fD1"
      },
      "source": [
        "report_df['positive_word_proportion'] = report_df.apply(lambda x:positive_word_proportion(x.positive_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_-U4XbN0iKF"
      },
      "source": [
        "report_df['negative_word_proportion'] = report_df.apply(lambda x:negative_word_proportion(x.negative_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncVYzgti0mKu"
      },
      "source": [
        "def uncertain_word_proportion(uncertainScore,wordcount):\n",
        "    uwp = 0\n",
        "    if wordcount !=0:\n",
        "        uwp = uncertainScore / wordcount\n",
        "    return uwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhDMpFbY0qeK"
      },
      "source": [
        "def constrain_word_proportion(constrainScore,wordcount):\n",
        "    cwp = 0\n",
        "    if wordcount !=0:\n",
        "        cwp = constrainScore / wordcount\n",
        "    return cwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MryKMi9g0tNt"
      },
      "source": [
        "report_df['uncertainty_word_proportion'] = report_df.apply(lambda x:uncertain_word_proportion(x.uncertainty_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAYBM64J0w5R"
      },
      "source": [
        "report_df['constraining_word_proportion'] = report_df.apply(lambda x:constrain_word_proportion(x.constraining_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e4sjQDQ01HI"
      },
      "source": [
        "report_df['constraining_words_whole_report'] = report_df['filtered'].apply(constraining_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PueqFT704F2"
      },
      "source": [
        "final_report = cik_list.join(report_df.iloc[:,3:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTuV8Uz06qA"
      },
      "source": [
        "final_report.to_csv('final_report.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}