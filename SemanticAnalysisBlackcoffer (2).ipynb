{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticAnalysisBlackcoffer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8TRJ1n6wPog"
      },
      "source": [
        "# Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_sWfMFDwTf0"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import string\n",
        "import time\n",
        "from nltk.tokenize import sent_tokenize, RegexpTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSb67EhFIxSa",
        "outputId": "a824d987-2352-4ccc-936c-2c5d957e8cdd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcCZF-iHApB4",
        "outputId": "4f9cb3a0-dba5-45e9-f0a1-b9530e1293d6"
      },
      "source": [
        "!pip3 install requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6FSXRmzAEFw"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyFgrd8nwjgI"
      },
      "source": [
        "# Importing cik List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYfyRiSCwjG0"
      },
      "source": [
        "cik_list = pd.read_csv('cik_list.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aez0FGoAw3nK"
      },
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm2jSK2XwiAw"
      },
      "source": [
        "def extract_data(link):\n",
        "    link = 'https://www.sec.gov/Archives/' + link.strip()\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"}\n",
        "    f = requests.get(link ,headers=headers)\n",
        "    text = f.text\n",
        "    return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZfOSX9FFcFA"
      },
      "source": [
        "report=cik_list['SECFNAME'].apply(extract_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xec3hfWxLVk"
      },
      "source": [
        "def clean_data(text):\n",
        "    #Remove HTML Tags\n",
        "    text = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});','', text)\n",
        "    \n",
        "    #remove extra line and tabs\n",
        "    text = text.replace('\\n',' ')\n",
        "    text = text.replace('\\t',' ')\n",
        "\n",
        "    #remove punctuation \n",
        "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # remove numbers and special characters\n",
        "    text = re.sub(r'[^a-zA-z.,!?/:;\\\"\\'\\s]',' ',text)\n",
        "    \n",
        "    #remove multiple spaces\n",
        "    text = re.sub('(?s) +',' ',text)\n",
        "   \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKGL9sYDxd9p"
      },
      "source": [
        "report_data = {'raw_text': report}\n",
        "report_df = pd.DataFrame(report_data)\n",
        "report_df['clean_data'] = report_df['raw_text'].apply(clean_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_l1rRzkxJ29"
      },
      "source": [
        "Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG6FrrcFxrXU"
      },
      "source": [
        "f = open(\"StopWords_Generic.txt\", \"r\")\n",
        "stop_words = f.read().lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYDryESFyVXM"
      },
      "source": [
        "stopWordList = stop_words.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWy46622yZcU"
      },
      "source": [
        "def tokenize_text(text):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+') #removing punctuation\n",
        "    tokens = tokenizer.tokenize(text.lower())\n",
        "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens)) # filtering stopwords\n",
        "    return filtered_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLdpxSKhycLQ"
      },
      "source": [
        "report_df['filtered'] = report_df['clean_data'].apply(tokenize_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFRefukuyfxE"
      },
      "source": [
        "positive_df = pd.read_csv('Positive-Table.csv')\n",
        "negative_df = pd.read_csv('Negative-Table.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLZm7hwEDlc8",
        "outputId": "898afb82-c17d-4f98-9de6-41393258488a"
      },
      "source": [
        "print(positive_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             ABLE\n",
            "0       ABUNDANCE\n",
            "1        ABUNDANT\n",
            "2       ACCLAIMED\n",
            "3      ACCOMPLISH\n",
            "4    ACCOMPLISHED\n",
            "..            ...\n",
            "348           WIN\n",
            "349        WINNER\n",
            "350       WINNERS\n",
            "351       WINNING\n",
            "352        WORTHY\n",
            "\n",
            "[353 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYlBBf_oyie_"
      },
      "source": [
        "positiveWords = positive_df.iloc[:,0].apply(lambda x:x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxXEH3L5GADK",
        "outputId": "6e78540c-e36d-4c8f-e330-97ed786a4f05"
      },
      "source": [
        "print(positiveWords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         abundance\n",
            "1          abundant\n",
            "2         acclaimed\n",
            "3        accomplish\n",
            "4      accomplished\n",
            "           ...     \n",
            "348             win\n",
            "349          winner\n",
            "350         winners\n",
            "351         winning\n",
            "352          worthy\n",
            "Name: ABLE, Length: 353, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvgUH9ivynIH"
      },
      "source": [
        "positiveWordsList = positiveWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOC7kmkHysGK"
      },
      "source": [
        "negativeWords = negative_df.iloc[:,0].apply(lambda x:x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Pa_cFryvLr"
      },
      "source": [
        "negativeWordsList = negativeWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWNzAyGayyCg"
      },
      "source": [
        "positiveWordsList = list(filter(lambda word: word not in stopWordList, positiveWordsList))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGJpa1ly1eN"
      },
      "source": [
        "negativeWordsList = list(filter(lambda word: word not in stopWordList, negativeWordsList))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDeI2b7jy78p"
      },
      "source": [
        "Positive and Negative Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKr82as5zAVB"
      },
      "source": [
        "def positive_score(token):\n",
        "    posWords = 0\n",
        "    for word in token:\n",
        "        if word in positiveWordsList:\n",
        "            posWords  += 1\n",
        "    return posWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrlbiB_fzEoq"
      },
      "source": [
        "def negative_score(token):\n",
        "    negWords=0\n",
        "    for word in token:\n",
        "        if word in negativeWordsList:\n",
        "            negWords -=1\n",
        "    return negWords*-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhhZ5t7BzIhL"
      },
      "source": [
        "def polarity_score(positiveScore, negativeScore):\n",
        "    pol_score = (positiveScore - negativeScore) / ((positiveScore + negativeScore) + 0.000001)\n",
        "    return pol_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg0lY7_VzLbu"
      },
      "source": [
        "report_df['positive_score'] = report_df['filtered'].apply(positive_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF4aY0vmzTUH"
      },
      "source": [
        "report_df['negative_score'] = report_df['filtered'].apply(negative_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0Gw7BYzXBf"
      },
      "source": [
        "report_df['polarity_score'] = report_df.apply(lambda x: polarity_score(x.positive_score,x.negative_score),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Xazbwmzaj3"
      },
      "source": [
        "def average_sentence_length(text,word_token):\n",
        "    sentence_token = sent_tokenize(text)\n",
        "    totalWordCount = len(word_token)\n",
        "    totalSentences = len(sentence_token)\n",
        "    average_sent_length = 0\n",
        "    if totalSentences != 0:\n",
        "        average_sent_length = totalWordCount / totalSentences    \n",
        "    return round(average_sent_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUbJm0DczeGv"
      },
      "source": [
        "\n",
        "report_df['average_sentence_length'] = report_df.apply(lambda x: average_sentence_length(x.clean_data,x.filtered),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3LmapTCzhfs"
      },
      "source": [
        "def syllable_count(word):\n",
        "    vowels = 0\n",
        "    word = word.lower()\n",
        "    if word.endswith(('es','ed')):\n",
        "            pass\n",
        "    else:\n",
        "        for w in word:\n",
        "            if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
        "                vowels += 1\n",
        "    return vowels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbyVod3FzljD"
      },
      "source": [
        "def complex_word_count(token):\n",
        "    complexWords = 0\n",
        "    for word in token:\n",
        "        if syllable_count(word) > 2:\n",
        "            complexWords+=1\n",
        "    return complexWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8IyAR5dzrPz"
      },
      "source": [
        "def complex_word_percentage(token):\n",
        "    totalWords = len(token)\n",
        "    complexWords = complex_word_count(token)\n",
        "    return complexWords/totalWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VOwitJKzu1H"
      },
      "source": [
        "report_df['percentage_of_complex_words'] = report_df['filtered'].apply(complex_word_percentage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB_SUyqfzy0N"
      },
      "source": [
        "def fog_index(avg_sentence_length,percentage_complex):\n",
        "    return 0.4*(avg_sentence_length+percentage_complex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TplRG1qfz2Bc"
      },
      "source": [
        "report_df['fog_index'] = report_df.apply(lambda x:fog_index(x.average_sentence_length,x.percentage_of_complex_words),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2j8C8oZz5ef"
      },
      "source": [
        "report_df['word_count'] = report_df['filtered'].apply(lambda x:len(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOXY5jnSz_xu"
      },
      "source": [
        "report_df['complex_word_count'] = report_df['filtered'].apply(complex_word_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6OKgMGo0DFH"
      },
      "source": [
        "\n",
        "uncertainty_df = pd.read_csv('uncertainty_dictionary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpu_Dfl_0Gpv"
      },
      "source": [
        "uncertainWords = uncertainty_df['Word'].apply(lambda x:x.lower())\n",
        "uncertainWordsList = uncertainWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdtOD4pn0Kbm"
      },
      "source": [
        "def uncertainty_score(token):\n",
        "    uncWords = 0\n",
        "    for word in token:\n",
        "        if word in uncertainWordsList:\n",
        "            uncWords  += 1\n",
        "    return uncWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs64-E1q0NKT"
      },
      "source": [
        "constraining_df = pd.read_csv('constraining_dictionary.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYjfka9VJpCX",
        "outputId": "3030e54e-0455-41d4-8f38-0df98f3adfb1"
      },
      "source": [
        "print(constraining_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              ABIDE\n",
            "0           ABIDING\n",
            "1             BOUND\n",
            "2           BOUNDED\n",
            "3            COMMIT\n",
            "4        COMMITMENT\n",
            "..              ...\n",
            "178        STRICTER\n",
            "179       STRICTEST\n",
            "180        STRICTLY\n",
            "181  UNAVAILABILITY\n",
            "182     UNAVAILABLE\n",
            "\n",
            "[183 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8ieeAB_JnhN"
      },
      "source": [
        "constrainWords = constraining_df.iloc[:,0].apply(lambda x:x.lower())\n",
        "constrainWordsList = constrainWords.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTqigUtd0P3z"
      },
      "source": [
        "def constraining_score(token):\n",
        "    constrainWords = 0\n",
        "    for word in token:\n",
        "        if word in constrainWordsList:\n",
        "            constrainWords  += 1\n",
        "    return constrainWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JTxC2DW0SoO"
      },
      "source": [
        "report_df['uncertainty_score'] = report_df['filtered'].apply(uncertainty_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC7eCP_i0VxD"
      },
      "source": [
        "report_df['constraining_score'] = report_df['filtered'].apply(constraining_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2m4QMDz0YxD"
      },
      "source": [
        "def positive_word_proportion(positiveScore,wordcount):\n",
        "    pwp = 0\n",
        "    if wordcount !=0:\n",
        "        pwp = positiveScore / wordcount\n",
        "    return pwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7bqsKcm0bWL"
      },
      "source": [
        "def negative_word_proportion(negativeScore,wordcount):\n",
        "    nwp = 0\n",
        "    if wordcount !=0:\n",
        "        nwp = negativeScore / wordcount\n",
        "    return nwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJNvHtKf0fD1"
      },
      "source": [
        "report_df['positive_word_proportion'] = report_df.apply(lambda x:positive_word_proportion(x.positive_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_-U4XbN0iKF"
      },
      "source": [
        "report_df['negative_word_proportion'] = report_df.apply(lambda x:negative_word_proportion(x.negative_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncVYzgti0mKu"
      },
      "source": [
        "def uncertain_word_proportion(uncertainScore,wordcount):\n",
        "    uwp = 0\n",
        "    if wordcount !=0:\n",
        "        uwp = uncertainScore / wordcount\n",
        "    return uwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhDMpFbY0qeK"
      },
      "source": [
        "def constrain_word_proportion(constrainScore,wordcount):\n",
        "    cwp = 0\n",
        "    if wordcount !=0:\n",
        "        cwp = constrainScore / wordcount\n",
        "    return cwp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MryKMi9g0tNt"
      },
      "source": [
        "report_df['uncertainty_word_proportion'] = report_df.apply(lambda x:uncertain_word_proportion(x.uncertainty_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAYBM64J0w5R"
      },
      "source": [
        "report_df['constraining_word_proportion'] = report_df.apply(lambda x:constrain_word_proportion(x.constraining_score,x.word_count),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e4sjQDQ01HI"
      },
      "source": [
        "report_df['constraining_words_whole_report'] = report_df['filtered'].apply(constraining_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PueqFT704F2"
      },
      "source": [
        "final_report = cik_list.join(report_df.iloc[:,3:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fTuV8Uz06qA"
      },
      "source": [
        "final_report.to_csv('Output.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}